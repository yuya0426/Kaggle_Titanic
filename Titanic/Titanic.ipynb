{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fvjsXdjoy2aDe-gXTOhUAexci8I0b1Ct",
      "authorship_tag": "ABX9TyMo4iHtw3NVl5+mmqVIGMA0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuya0426/Kaggle_Titanic/blob/main/Titanic/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "APIキーの取得"
      ],
      "metadata": {
        "id": "5YY-fMrY801F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. ここをご自身の文字列に書き換えてください\n",
        "\n",
        "\n",
        "# 2. データをダウンロードして解凍\n",
        "!kaggle competitions download -c titanic\n",
        "!unzip -o titanic.zip\n",
        "\n",
        "# 3. データを読み込み\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# # 4. データの中身を表示\n",
        "# print(\"【データの中身（先頭5行）】\")\n",
        "# display(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8XwgFW577mA",
        "outputId": "c417a691-8af8-44b9-a071-16f6e9028567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading titanic.zip to /content\n",
            "\r  0% 0.00/34.1k [00:00<?, ?B/s]\n",
            "\r100% 34.1k/34.1k [00:00<00:00, 128MB/s]\n",
            "Archive:  titanic.zip\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "年齢の欠損を中央値で補償する"
      ],
      "metadata": {
        "id": "iskiRBKfJAwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cakQgBbJRY9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "1cec0d6f-a2ed-4277-c165-ea92d7d0278a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【処理後のAgeの欠損値の数】\n",
            "Trainデータ: 0\n",
            "\n",
            "【AIに学習させるデータ（X_train）の先頭5行】\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Pclass   Age\n",
              "0       3  22.0\n",
              "1       1  38.0\n",
              "2       3  26.0\n",
              "3       1  35.0\n",
              "4       3  35.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae9d941d-d1a9-4fe1-afc6-5869003f21e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae9d941d-d1a9-4fe1-afc6-5869003f21e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae9d941d-d1a9-4fe1-afc6-5869003f21e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae9d941d-d1a9-4fe1-afc6-5869003f21e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(X_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.833739825307955,\n        \"min\": 22.0,\n        \"max\": 38.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          38.0,\n          35.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 今回特徴量として使う列を指定\n",
        "features = ['Pclass', 'Age']\n",
        "\n",
        "# 欠損値の処理：Ageの空欄を、全体の「年齢の中央値」でそっと埋める\n",
        "age_median = train_df['Age'].median()\n",
        "train_df['Age'] = train_df['Age'].fillna(age_median)\n",
        "test_df['Age'] = test_df['Age'].fillna(age_median)\n",
        "\n",
        "# AIに学習させるためのデータ(X)と、予測させたい正解データ(y)に分割する\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# テスト用のデータも同じように準備する\n",
        "X_test = test_df[features]\n",
        "\n",
        "# 本当に空欄（欠損値）が埋まったか確認\n",
        "print(\"【処理後のAgeの欠損値の数】\")\n",
        "print(\"Trainデータ:\", X_train['Age'].isnull().sum())\n",
        "\n",
        "# AIに渡す直前のデータの中身を確認\n",
        "print(\"\\n【AIに学習させるデータ（X_train）の先頭5行】\")\n",
        "display(X_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kFoldとLightGBMを実行"
      ],
      "metadata": {
        "id": "dH-pafI-fxoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# 1. 5分割の交差検証（KFold）の設定\n",
        "# shuffle=Trueでデータをシャッフルしてから分割し、random_stateで毎回同じ分け方になるよう固定します\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 各回の正解率を保存しておくための空リスト\n",
        "accuracies = []\n",
        "\n",
        "# 2. 5回のループ処理（学習と検証）\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    print(f\"--- Fold {fold + 1} ---\")\n",
        "\n",
        "    # 手元のデータを「学習用(4/5)」と「検証用(1/5)」に切り分ける\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # LightGBMが読み込める専用のデータ形式に変換\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    # LightGBMの基本的な設定（ハイパーパラメータ）\n",
        "    params = {\n",
        "        'objective': 'binary',     # 目的：0(死亡)か1(生存)かの「2値分類」\n",
        "        'metric': 'binary_error',  # 評価指標：エラー率\n",
        "        'verbosity': -1            # 余計な警告文を出さない設定\n",
        "    }\n",
        "\n",
        "    # 3. モデルの学習を実行\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        lgb_train,\n",
        "        valid_sets=[lgb_train, lgb_eval],\n",
        "        num_boost_round=100        # 最大100回学習を繰り返す\n",
        "    )\n",
        "\n",
        "    # 4. 学習したモデルを使って、検証用データ(X_val)の生存予測を行う\n",
        "    # ※LightGBMは「生存する確率（0.0〜1.0）」を出力します\n",
        "    y_pred_prob = model.predict(X_val)\n",
        "\n",
        "    # 確率が0.5以上なら生存(1)、0.5未満なら死亡(0)に変換\n",
        "    y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "\n",
        "    # 5. 実際の正解(y_val)と予測(y_pred)を比較し、正解率を計算\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    print(f\"Fold {fold + 1} の正解率: {acc:.4f}\\n\")\n",
        "\n",
        "    # リストに正解率を追加\n",
        "    accuracies.append(acc)\n",
        "\n",
        "# 6. 全5回の平均正解率を出力\n",
        "print(\"==================================\")\n",
        "print(f\"★ 5分割交差検証の平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lBXGcToJAXG",
        "outputId": "2bcc34e4-689c-4493-f707-48ce21d9570f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 1 ---\n",
            "Fold 1 の正解率: 0.7207\n",
            "\n",
            "--- Fold 2 ---\n",
            "Fold 2 の正解率: 0.6685\n",
            "\n",
            "--- Fold 3 ---\n",
            "Fold 3 の正解率: 0.6573\n",
            "\n",
            "--- Fold 4 ---\n",
            "Fold 4 の正解率: 0.6685\n",
            "\n",
            "--- Fold 5 ---\n",
            "Fold 5 の正解率: 0.6517\n",
            "\n",
            "==================================\n",
            "★ 5分割交差検証の平均正解率: 0.6733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "特徴量に「性別」を追加 <br>\n",
        "「性別」の属性を数値に変換"
      ],
      "metadata": {
        "id": "xVjUhdShg8k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# 1. 新しいパーツ（性別）を数字に変換する前処理\n",
        "# .map()という工具を使って、maleを0、femaleを1に置き換えます\n",
        "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
        "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 2. 特徴量のリストに 'Sex' を追加！\n",
        "features = ['Pclass', 'Age', 'Sex']\n",
        "\n",
        "# AIに渡すための問題(X)を新しい特徴量で作り直す\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived'] # 正解(y)はそのまま\n",
        "\n",
        "# 3. KFoldの設定（先ほどと同じ5分割）\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "print(\"新しい特徴量 'Sex' を追加して学習開始...\\n\")\n",
        "\n",
        "# 4. 学習と検証のループ（先ほどと全く同じ処理です）\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "\n",
        "    # データの切り分け\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # LightGBM用のオブジェクト(箱)に変換\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    # 設定\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'verbosity': -1\n",
        "    }\n",
        "\n",
        "    # 学習\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=100)\n",
        "\n",
        "    # 予測と正解率の計算\n",
        "    y_pred_prob = model.predict(X_val)\n",
        "    y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    print(f\"Fold {fold + 1} の正解率: {acc:.4f}\")\n",
        "    accuracies.append(acc)\n",
        "\n",
        "# 5. 結果発表\n",
        "print(\"==================================\")\n",
        "print(f\"★ 5分割交差検証の平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGzz7iuxhW0a",
        "outputId": "d48d289b-2d3d-4f1d-ef11-3cf6464acc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新しい特徴量 'Sex' を追加して学習開始...\n",
            "\n",
            "Fold 1 の正解率: 0.8380\n",
            "Fold 2 の正解率: 0.7865\n",
            "Fold 3 の正解率: 0.8483\n",
            "Fold 4 の正解率: 0.7697\n",
            "Fold 5 の正解率: 0.8090\n",
            "==================================\n",
            "★ 5分割交差検証の平均正解率: 0.8103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optunaの導入"
      ],
      "metadata": {
        "id": "gNrjp21kiKNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Optunaのインストールとインポート\n",
        "!pip install optuna\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# 2. 目的関数（Optunaに「何をどう調整して、何を良くしたいか」を教えるルールブック）\n",
        "def objective(trial):\n",
        "    # Optunaに回してもらうダイヤル（パラメータ）の範囲を指定\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'verbosity': -1,\n",
        "        # ここからがOptunaにお任せする設定値\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 50),\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    accuracies = []\n",
        "\n",
        "    # 5分割交差検証で、その設定値の「実力」を測る\n",
        "    for train_idx, val_idx in kf.split(X_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "        lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "        # Optunaが選んだパラメータを使ってLightGBMを学習\n",
        "        model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=100)\n",
        "\n",
        "        y_pred_prob = model.predict(X_val)\n",
        "        y_pred = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    # 5回の平均正解率をOptunaに報告する\n",
        "    return np.mean(accuracies)\n",
        "\n",
        "print(\"Optunaによる最強のセッティング探索を開始します...\\n\")\n",
        "\n",
        "# 3. Optunaに「正解率を最大化(maximize)する方向で、20パターン試して！」と命令\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# 4. 結果発表\n",
        "print(\"==================================\")\n",
        "print(\"★ 最適化完了！\")\n",
        "print(f\"一番良かった正解率: {study.best_value:.4f}\")\n",
        "print(\"その時の最強パラメータ:\", study.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4A7iEnGiNY7",
        "outputId": "017d7959-cdf6-4e36-ab82-a877485a7525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.3)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-17 12:17:56,740] A new study created in memory with name: no-name-a05e21e1-6279-4a07-9188-e4adde7cf9fd\n",
            "[I 2026-02-17 12:17:56,882] Trial 0 finished with value: 0.7957378695624883 and parameters: {'learning_rate': 0.062070531382035644, 'max_depth': 4, 'num_leaves': 42}. Best is trial 0 with value: 0.7957378695624883.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optunaによる最強のセッティング探索を開始します...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-17 12:17:57,076] Trial 1 finished with value: 0.8002134203753688 and parameters: {'learning_rate': 0.06698497906796695, 'max_depth': 8, 'num_leaves': 13}. Best is trial 1 with value: 0.8002134203753688.\n",
            "[I 2026-02-17 12:17:57,251] Trial 2 finished with value: 0.8125478626577113 and parameters: {'learning_rate': 0.09711414033423715, 'max_depth': 6, 'num_leaves': 21}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:57,381] Trial 3 finished with value: 0.7990961019396146 and parameters: {'learning_rate': 0.08929006815691565, 'max_depth': 4, 'num_leaves': 10}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:57,552] Trial 4 finished with value: 0.7991023790094783 and parameters: {'learning_rate': 0.055068969015145276, 'max_depth': 6, 'num_leaves': 46}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:57,698] Trial 5 finished with value: 0.7878789780930262 and parameters: {'learning_rate': 0.024632648910347776, 'max_depth': 4, 'num_leaves': 22}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:57,883] Trial 6 finished with value: 0.7912497646098801 and parameters: {'learning_rate': 0.016693590159786182, 'max_depth': 7, 'num_leaves': 24}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,061] Trial 7 finished with value: 0.7901261691042623 and parameters: {'learning_rate': 0.014635942147284385, 'max_depth': 4, 'num_leaves': 48}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,208] Trial 8 finished with value: 0.7980038917833154 and parameters: {'learning_rate': 0.046382573739450136, 'max_depth': 4, 'num_leaves': 23}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,327] Trial 9 finished with value: 0.7890025735986441 and parameters: {'learning_rate': 0.017281095406544537, 'max_depth': 3, 'num_leaves': 46}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,540] Trial 10 finished with value: 0.7878789780930261 and parameters: {'learning_rate': 0.02832955886844662, 'max_depth': 9, 'num_leaves': 34}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,693] Trial 11 finished with value: 0.8103006716464755 and parameters: {'learning_rate': 0.08776578813093211, 'max_depth': 7, 'num_leaves': 11}. Best is trial 2 with value: 0.8125478626577113.\n",
            "[I 2026-02-17 12:17:58,866] Trial 12 finished with value: 0.8125541397275751 and parameters: {'learning_rate': 0.09531458064696166, 'max_depth': 8, 'num_leaves': 16}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:17:59,073] Trial 13 finished with value: 0.7957378695624883 and parameters: {'learning_rate': 0.03967700671986183, 'max_depth': 6, 'num_leaves': 18}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:17:59,280] Trial 14 finished with value: 0.8058062896240035 and parameters: {'learning_rate': 0.09424909713211632, 'max_depth': 9, 'num_leaves': 31}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:17:59,461] Trial 15 finished with value: 0.8035842068922229 and parameters: {'learning_rate': 0.07315220859780541, 'max_depth': 7, 'num_leaves': 18}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:17:59,658] Trial 16 finished with value: 0.8002196974452325 and parameters: {'learning_rate': 0.03762121221442606, 'max_depth': 8, 'num_leaves': 27}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:17:59,820] Trial 17 finished with value: 0.8080723118448307 and parameters: {'learning_rate': 0.0971327683284125, 'max_depth': 5, 'num_leaves': 17}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:18:00,017] Trial 18 finished with value: 0.785638064151654 and parameters: {'learning_rate': 0.01105766783547845, 'max_depth': 8, 'num_leaves': 36}. Best is trial 12 with value: 0.8125541397275751.\n",
            "[I 2026-02-17 12:18:00,198] Trial 19 finished with value: 0.7901387232439897 and parameters: {'learning_rate': 0.04778172353486915, 'max_depth': 5, 'num_leaves': 14}. Best is trial 12 with value: 0.8125541397275751.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\n",
            "★ 最適化完了！\n",
            "一番良かった正解率: 0.8126\n",
            "その時の最強パラメータ: {'learning_rate': 0.09531458064696166, 'max_depth': 8, 'num_leaves': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "提出用ファイルの作成"
      ],
      "metadata": {
        "id": "jEaNbcS-iqhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ★ ここが抜けていました！X_testにも「Sex」を含めた3つの特徴量をセットし直します\n",
        "features = ['Pclass', 'Age', 'Sex']\n",
        "X_test = test_df[features]\n",
        "\n",
        "# 1. Optunaが見つけた最強パラメータを取得し、基本設定を追加\n",
        "best_params = study.best_params\n",
        "best_params['objective'] = 'binary'\n",
        "best_params['metric'] = 'binary_error'\n",
        "best_params['verbosity'] = -1\n",
        "\n",
        "print(\"【最終モデルの学習を開始します】\")\n",
        "print(\"使用するパラメータ:\", best_params)\n",
        "\n",
        "# 2. 手元にある学習データ「全体」を使って、最終モデルを鍛え上げる\n",
        "lgb_train_final = lgb.Dataset(X_train, y_train)\n",
        "final_model = lgb.train(best_params, lgb_train_final, num_boost_round=100)\n",
        "\n",
        "# 3. 本番テストデータ (X_test) に対する予測を実行！\n",
        "y_pred_prob_test = final_model.predict(X_test)\n",
        "y_pred_test = np.where(y_pred_prob_test >= 0.5, 1, 0)\n",
        "\n",
        "# 4. Kaggleの提出ルールに合わせて、データフレーム（表）を作成\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_df['PassengerId'], # 乗客のID\n",
        "    'Survived': y_pred_test                # あなたのAIが予測した生死\n",
        "})\n",
        "\n",
        "# 5. CSVファイルとして保存（index=False は余計な行番号を消すおまじないです）\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\n==================================\")\n",
        "print(\"★ 提出用ファイル 'submission.csv' が無事に作成されました！\")\n",
        "display(submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "MzpoVUKpixXv",
        "outputId": "4da5771e-b026-4efc-c3a6-f0508c03e392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【最終モデルの学習を開始します】\n",
            "使用するパラメータ: {'learning_rate': 0.09531458064696166, 'max_depth': 8, 'num_leaves': 16, 'objective': 'binary', 'metric': 'binary_error', 'verbosity': -1}\n",
            "\n",
            "==================================\n",
            "★ 提出用ファイル 'submission.csv' が無事に作成されました！\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84bd813f-cd67-462b-958a-72715d1e5e1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84bd813f-cd67-462b-958a-72715d1e5e1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84bd813f-cd67-462b-958a-72715d1e5e1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84bd813f-cd67-462b-958a-72715d1e5e1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(submission\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 892,\n        \"max\": 896,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          893,\n          896,\n          894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggleに提出"
      ],
      "metadata": {
        "id": "gAcWGqHlk9Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ9FfG5XjugQ",
        "outputId": "14583c99-9eb0-4020-8b70-b0141b54a78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 3.97kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み直し（リセット）\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 1. 前処理：性別（Sex）を数値に変換\n",
        "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
        "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# ★ ポイント：今回は「年齢（Age）」を使わず、この2つだけで挑みます\n",
        "features = ['Pclass', 'Sex']\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# 2. 5分割交差検証で実力を測る\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "print(f\"使用する特徴量: {features}\")\n",
        "print(\"学習開始...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    params = {'objective': 'binary', 'metric': 'binary_error', 'verbosity': -1}\n",
        "\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=100)\n",
        "\n",
        "    y_pred = np.where(model.predict(X_val) >= 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"★ 平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH4czAfyFPZu",
        "outputId": "9be89298-fe22-4276-a0d5-b0320ae5b744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用する特徴量: ['Pclass', 'Sex']\n",
            "学習開始...\n",
            "\n",
            "==================================\n",
            "★ 平均正解率: 0.7767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み直し\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 1. 前処理：性別の変換\n",
        "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
        "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 2. 前処理：欠損値の処理（AgeとEmbarked）\n",
        "# Ageは使わないかもしれませんが、念のため埋めておきます\n",
        "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
        "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
        "# Embarked（乗船港）は2つだけ欠損があるので、一番多い 'S' で埋めます\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
        "test_df['Embarked'] = test_df['Embarked'].fillna('S')\n",
        "\n",
        "# Embarkedを数値に変換 (S=0, C=1, Q=2)\n",
        "embarked_map = {'S': 0, 'C': 1, 'Q': 2}\n",
        "train_df['Embarked'] = train_df['Embarked'].map(embarked_map)\n",
        "test_df['Embarked'] = test_df['Embarked'].map(embarked_map)\n",
        "\n",
        "# ★ ここが新技術！「家族の人数」を作る\n",
        "# 兄弟配偶者 + 親子 + 自分(1) = 家族の人数\n",
        "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
        "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
        "\n",
        "# ★ 特徴量を厳選！\n",
        "# Ageを入れるかどうかは、実験1の結果次第で決めてみてください\n",
        "features = ['Pclass', 'Sex', 'FamilySize', 'Embarked']\n",
        "\n",
        "# 以下、学習用データ作成\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# 5分割交差検証（先ほどと同じコード）を実行\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "print(f\"新しい特徴量セット: {features}\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    # 警告を減らすためパラメータを少し調整\n",
        "    params = {'objective': 'binary', 'metric': 'binary_error', 'verbosity': -1}\n",
        "\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=100)\n",
        "\n",
        "    y_pred = np.where(model.predict(X_val) >= 0.5, 1, 0)\n",
        "    accuracies.append(accuracy_score(y_val, y_pred))\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"★ 平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-QZuO8kF3Nw",
        "outputId": "67c85579-1c13-48b7-f2d1-74754cc0bdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新しい特徴量セット: ['Pclass', 'Sex', 'FamilySize', 'Embarked']\n",
            "==================================\n",
            "★ 平均正解率: 0.7834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み直し\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 1. 性別(Sex)と出港地(Embarked)を数値に変換\n",
        "train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\n",
        "test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
        "test_df['Embarked'] = test_df['Embarked'].fillna('S')\n",
        "train_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "test_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "\n",
        "# 2. 年齢(Age)を復活！欠損値は中央値で埋める\n",
        "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
        "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
        "\n",
        "# 3. 家族の人数(FamilySize)を追加\n",
        "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
        "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
        "\n",
        "# ★ 今回のオールスター特徴量\n",
        "features = ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked']\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# 5分割交差検証\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "print(f\"★ 使用する特徴量: {features}\")\n",
        "print(\"学習開始...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    params = {'objective': 'binary', 'metric': 'binary_error', 'verbosity': -1}\n",
        "\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=100)\n",
        "\n",
        "    y_pred = np.where(model.predict(X_val) >= 0.5, 1, 0)\n",
        "    accuracies.append(accuracy_score(y_val, y_pred))\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"★ 平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJTTS_AmG3ly",
        "outputId": "3f826675-24a8-4788-b5e5-6d6369871c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ 使用する特徴量: ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked']\n",
            "学習開始...\n",
            "\n",
            "==================================\n",
            "★ 平均正解率: 0.8238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold # ★ KFoldの進化版\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み直し\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# =================================================\n",
        "# 1. 前処理：名前から「敬称(Title)」を抜き出す魔法\n",
        "# =================================================\n",
        "# データを結合して一気に処理します\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# 名前の中から \"Mr.\" などの敬称を抽出\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "# 敬称を主要なグループにまとめる（DrやRevなどは \"Others\" に）\n",
        "title_mapping = {\n",
        "    \"Mr\": 0, \"Miss\": 1, \"Mrs\": 2,\n",
        "    \"Master\": 3, \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 1, \"Countess\": 2,\n",
        "    \"Ms\": 1, \"Lady\": 2, \"Jonkheer\": 4, \"Don\": 4, \"Dona\": 4, \"Mme\": 2, \"Capt\": 4, \"Sir\": 4\n",
        "}\n",
        "combined['Title'] = combined['Title'].map(title_mapping)\n",
        "# まとまらなかったものをその他(4)にする\n",
        "combined['Title'] = combined['Title'].fillna(4)\n",
        "\n",
        "# =================================================\n",
        "# 2. その他の前処理（これまでのおさらい）\n",
        "# =================================================\n",
        "# 性別\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 年齢（敬称ごとの中央値で埋めるのが実は最強ですが、今回は全体の中央値でシンプルに）\n",
        "combined['Age'] = combined['Age'].fillna(combined['Age'].median())\n",
        "\n",
        "# 家族の人数\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "\n",
        "# 出港地\n",
        "combined['Embarked'] = combined['Embarked'].fillna('S')\n",
        "combined['Embarked'] = combined['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "\n",
        "# ★ 運賃(Fare)を追加！\n",
        "# テストデータに1つだけ欠損があるので中央値で埋めます\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "\n",
        "# データを再び分離\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "# =================================================\n",
        "# 3. 学習開始\n",
        "# =================================================\n",
        "# ★ 今回の特徴量：敬称(Title)と運賃(Fare)が新入りです\n",
        "features = ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked', 'Fare', 'Title']\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# ★ 進化ポイント：StratifiedKFold\n",
        "# 生存者と死亡者の割合を崩さずに分割してくれる、KFoldの上位互換です\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "print(f\"★ 使用する特徴量: {features}\")\n",
        "print(\"学習開始...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    # 精度を上げるため、少しパラメータを調整（学習率を下げて回数を増やす）\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'verbosity': -1,\n",
        "        'learning_rate': 0.05,  # 慎重に学習\n",
        "        'num_leaves': 31        # 木の複雑さ\n",
        "    }\n",
        "\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval],\n",
        "                      num_boost_round=1000,        # 最大1000回\n",
        "                      callbacks=[lgb.early_stopping(stopping_rounds=50), # 50回改善しなければストップ\n",
        "                                 lgb.log_evaluation(period=0)] # ログを黙らせる\n",
        "                     )\n",
        "\n",
        "    y_pred = np.where(model.predict(X_val) >= 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"★ 平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmvubjolH4sl",
        "outputId": "efe3d7a8-2359-46d4-f262-3b553b17b69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:18: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:18: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-3374716869.py:18: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ 使用する特徴量: ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked', 'Fare', 'Title']\n",
            "学習開始...\n",
            "\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[70]\ttraining's binary_error: 0.108146\tvalid_1's binary_error: 0.134078\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_error: 0.13885\tvalid_1's binary_error: 0.134831\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[26]\ttraining's binary_error: 0.12763\tvalid_1's binary_error: 0.157303\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[9]\ttraining's binary_error: 0.16129\tvalid_1's binary_error: 0.162921\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[84]\ttraining's binary_error: 0.0939691\tvalid_1's binary_error: 0.129213\n",
            "==================================\n",
            "★ 平均正解率: 0.8563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# データの読み直し\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# =================================================\n",
        "# 1. 既存の強力な特徴量（おさらい）\n",
        "# =================================================\n",
        "# Title（敬称）\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "title_mapping = {\n",
        "    \"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3,\n",
        "    \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 1, \"Countess\": 2,\n",
        "    \"Ms\": 1, \"Lady\": 2, \"Jonkheer\": 4, \"Don\": 4, \"Dona\": 4, \"Mme\": 2, \"Capt\": 4, \"Sir\": 4\n",
        "}\n",
        "combined['Title'] = combined['Title'].map(title_mapping).fillna(4)\n",
        "\n",
        "# 性別、年齢、家族、出港地、運賃\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1})\n",
        "combined['Age'] = combined['Age'].fillna(combined['Age'].median())\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "combined['Embarked'] = combined['Embarked'].fillna('S').map({'S': 0, 'C': 1, 'Q': 2})\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "\n",
        "# =================================================\n",
        "# 2. 【新機能】Cabinから「デッキ」を抽出\n",
        "# =================================================\n",
        "# C85 -> C, D26 -> D のように先頭の文字を取る\n",
        "# 欠損値は 'M' (Missing) という新しいカテゴリにする\n",
        "combined['Deck'] = combined['Cabin'].astype(str).str[0]\n",
        "deck_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7, 'n': 8} # n is nan\n",
        "combined['Deck'] = combined['Deck'].map(deck_mapping)\n",
        "# マッピングできなかったものを8(Missing)にする\n",
        "combined['Deck'] = combined['Deck'].fillna(8)\n",
        "\n",
        "# =================================================\n",
        "# 3. 【新機能】チケットの重複枚数（TicketGroup）\n",
        "# =================================================\n",
        "# 自分と同じチケット番号を持っている人が何人いるか？\n",
        "# 家族だけでなく、友人や恋人も炙り出せる\n",
        "ticket_counts = combined['Ticket'].value_counts()\n",
        "combined['TicketGroup'] = combined['Ticket'].map(ticket_counts)\n",
        "\n",
        "# =================================================\n",
        "# データの分割と学習\n",
        "# =================================================\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "# 特徴量リスト：DeckとTicketGroupが追加されました\n",
        "features = ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked', 'Fare', 'Title', 'Deck', 'TicketGroup']\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "\n",
        "# 学習設定（少し複雑なモデルなので、過学習を防ぐ設定を強めます）\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "print(f\"★ 使用する特徴量: {features}\")\n",
        "print(\"学習開始...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
        "\n",
        "    # パラメータ調整：特徴量が増えたので少し「木の深さ」を制限して過学習抑制\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'verbosity': -1,\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 20,      # 少し小さくして単純化\n",
        "        'max_depth': 7,        # 深すぎないように制限\n",
        "        'min_data_in_leaf': 20 # 葉っぱ1つあたりのデータ数を確保\n",
        "    }\n",
        "\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval],\n",
        "                      num_boost_round=1000,\n",
        "                      callbacks=[lgb.early_stopping(stopping_rounds=50),\n",
        "                                 lgb.log_evaluation(period=0)]\n",
        "                     )\n",
        "\n",
        "    y_pred = np.where(model.predict(X_val) >= 0.5, 1, 0)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "print(\"==================================\")\n",
        "print(f\"★ 平均正解率: {np.mean(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-DxCX6yIZXh",
        "outputId": "91a8a6f6-3c70-40ed-99b6-82758885012d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-910027170.py:16: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ 使用する特徴量: ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked', 'Fare', 'Title', 'Deck', 'TicketGroup']\n",
            "学習開始...\n",
            "\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[39]\ttraining's binary_error: 0.134831\tvalid_1's binary_error: 0.128492\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[54]\ttraining's binary_error: 0.12763\tvalid_1's binary_error: 0.134831\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[25]\ttraining's binary_error: 0.12763\tvalid_1's binary_error: 0.157303\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttraining's binary_error: 0.11641\tvalid_1's binary_error: 0.157303\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[26]\ttraining's binary_error: 0.131837\tvalid_1's binary_error: 0.168539\n",
            "==================================\n",
            "★ 平均正解率: 0.8507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# データの読み直し\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# =================================================\n",
        "# 1. 特徴量エンジニアリング（ベストスコア0.8563の構成）\n",
        "# =================================================\n",
        "# Title（敬称）\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "title_mapping = {\n",
        "    \"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3,\n",
        "    \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 1, \"Countess\": 2,\n",
        "    \"Ms\": 1, \"Lady\": 2, \"Jonkheer\": 4, \"Don\": 4, \"Dona\": 4, \"Mme\": 2, \"Capt\": 4, \"Sir\": 4\n",
        "}\n",
        "combined['Title'] = combined['Title'].map(title_mapping).fillna(4)\n",
        "\n",
        "# 性別\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 年齢（欠損値処理）\n",
        "combined['Age'] = combined['Age'].fillna(combined['Age'].median())\n",
        "\n",
        "# 家族の人数\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "\n",
        "# 出港地\n",
        "combined['Embarked'] = combined['Embarked'].fillna('S').map({'S': 0, 'C': 1, 'Q': 2})\n",
        "\n",
        "# 運賃\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "\n",
        "# データを分割\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "# 使用する特徴量（ベストメンバー）\n",
        "features = ['Pclass', 'Sex', 'Age', 'FamilySize', 'Embarked', 'Fare', 'Title']\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Survived']\n",
        "X_test = test_df[features]\n",
        "\n",
        "# =================================================\n",
        "# 2. アンサンブル学習開始\n",
        "# =================================================\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 結果を保存するリスト\n",
        "lgb_accuracies = []\n",
        "rf_accuracies = []\n",
        "ensemble_accuracies = []\n",
        "\n",
        "print(\"★ アンサンブル学習（LightGBM + Random Forest）を開始します...\\n\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # --- モデル1: LightGBM ---\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_error',\n",
        "        'verbosity': -1,\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 31\n",
        "    }\n",
        "    model_lgb = lgb.train(lgb_params, lgb_train, num_boost_round=100)\n",
        "    # 予測（確率 0.0〜1.0）\n",
        "    prob_lgb = model_lgb.predict(X_val)\n",
        "\n",
        "    # --- モデル2: Random Forest ---\n",
        "    # ランダムフォレストはパラメータ調整なしでもそこそこ強いです\n",
        "    model_rf = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
        "    model_rf.fit(X_tr, y_tr)\n",
        "    # 予測（確率 0.0〜1.0）\n",
        "    prob_rf = model_rf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # --- ★ 合体（アンサンブル） ---\n",
        "    # 2つのAIの確率を平均します（LightGBM 50% + Random Forest 50%）\n",
        "    prob_ensemble = (prob_lgb + prob_rf) / 2\n",
        "\n",
        "    # 精度確認\n",
        "    y_pred_lgb = np.where(prob_lgb >= 0.5, 1, 0)\n",
        "    y_pred_rf = np.where(prob_rf >= 0.5, 1, 0)\n",
        "    y_pred_ensemble = np.where(prob_ensemble >= 0.5, 1, 0)\n",
        "\n",
        "    acc_lgb = accuracy_score(y_val, y_pred_lgb)\n",
        "    acc_rf = accuracy_score(y_val, y_pred_rf)\n",
        "    acc_ens = accuracy_score(y_val, y_pred_ensemble)\n",
        "\n",
        "    lgb_accuracies.append(acc_lgb)\n",
        "    rf_accuracies.append(acc_rf)\n",
        "    ensemble_accuracies.append(acc_ens)\n",
        "\n",
        "    print(f\"Fold {fold+1} | LGB: {acc_lgb:.4f} | RF: {acc_rf:.4f} | ★Ensemble: {acc_ens:.4f}\")\n",
        "\n",
        "print(\"\\n==================================\")\n",
        "print(f\"LGB平均: {np.mean(lgb_accuracies):.4f}\")\n",
        "print(f\"RF平均:  {np.mean(rf_accuracies):.4f}\")\n",
        "print(f\"★ アンサンブル平均: {np.mean(ensemble_accuracies):.4f}\")\n",
        "\n",
        "# =================================================\n",
        "# 3. 本番用データの作成\n",
        "# =================================================\n",
        "# 全データで再学習\n",
        "# LightGBM\n",
        "lgb_train_final = lgb.Dataset(X_train, y_train)\n",
        "model_lgb_final = lgb.train(lgb_params, lgb_train_final, num_boost_round=100)\n",
        "prob_lgb_test = model_lgb_final.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "model_rf_final = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
        "model_rf_final.fit(X_train, y_train)\n",
        "prob_rf_test = model_rf_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 平均をとる\n",
        "prob_ensemble_test = (prob_lgb_test + prob_rf_test) / 2\n",
        "y_pred_test = np.where(prob_ensemble_test >= 0.5, 1, 0)\n",
        "\n",
        "# 提出ファイル作成\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_df['PassengerId'],\n",
        "    'Survived': y_pred_test\n",
        "})\n",
        "submission.to_csv('submission_ensemble.csv', index=False)\n",
        "print(\"提出ファイル 'submission_ensemble.csv' を作成しました！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3nNCDJKJB-z",
        "outputId": "c082da41-3673-4a05-a467-6eaf0e97f612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-2542058255.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ アンサンブル学習（LightGBM + Random Forest）を開始します...\n",
            "\n",
            "Fold 1 | LGB: 0.8380 | RF: 0.8324 | ★Ensemble: 0.8436\n",
            "Fold 2 | LGB: 0.8315 | RF: 0.8315 | ★Ensemble: 0.8315\n",
            "Fold 3 | LGB: 0.8933 | RF: 0.8708 | ★Ensemble: 0.8933\n",
            "Fold 4 | LGB: 0.8202 | RF: 0.7978 | ★Ensemble: 0.8146\n",
            "Fold 5 | LGB: 0.8371 | RF: 0.8483 | ★Ensemble: 0.8539\n",
            "\n",
            "==================================\n",
            "LGB平均: 0.8440\n",
            "RF平均:  0.8361\n",
            "★ アンサンブル平均: 0.8474\n",
            "提出ファイル 'submission_ensemble.csv' を作成しました！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission_ensemble.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVIdoHDUJOCp",
        "outputId": "13ad05af-ddbb-4fcf-d7cb-add96c0df5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 14.0kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# =================================================\n",
        "# 1. データの読み込みと結合\n",
        "# =================================================\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# =================================================\n",
        "# 2. 特徴量エンジニアリング（汎化性能重視）\n",
        "# =================================================\n",
        "\n",
        "# --- Title（敬称）の抽出と整理 ---\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "# 稀な敬称をまとめてシンプルにする\n",
        "combined['Title'] = combined['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "combined['Title'] = combined['Title'].replace('Mlle', 'Miss')\n",
        "combined['Title'] = combined['Title'].replace('Ms', 'Miss')\n",
        "combined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n",
        "# 数値に変換\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "combined['Title'] = combined['Title'].map(title_mapping).fillna(0)\n",
        "\n",
        "# --- Sex（性別） ---\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "\n",
        "# --- Age（年齢）の補完とBinning（グルーピング） ---\n",
        "# 敬称ごとの中央値で年齢を埋める（これが最も精度が高い）\n",
        "combined['Age'] = combined['Age'].fillna(combined.groupby('Title')['Age'].transform('median'))\n",
        "\n",
        "# 年齢をそのまま使わず、5つのグループに分ける（Binning）\n",
        "# 0:子供, 1:若者, 2:成人, 3:中年, 4:老人\n",
        "combined['AgeBin'] = pd.cut(combined['Age'], 5, labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "# --- Embarked（出港地） ---\n",
        "combined['Embarked'] = combined['Embarked'].fillna(combined['Embarked'].mode()[0])\n",
        "combined['Embarked'] = combined['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
        "\n",
        "# --- Fare（運賃）の補完とBinning ---\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "# 運賃を4つの等分グループに分ける（四分位数）\n",
        "# これにより「高い」「安い」といった感覚的な分類が可能になる\n",
        "combined['FareBin'] = pd.qcut(combined['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n",
        "\n",
        "# --- FamilySize（家族サイズ）のグルーピング ---\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "# 家族の人数も「1人」「小家族」「大家族」に単純化する\n",
        "combined['IsAlone'] = 0\n",
        "combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
        "\n",
        "# =================================================\n",
        "# 3. データセットの準備\n",
        "# =================================================\n",
        "# 不要な列を削除（AgeやFareなどの「生の値」は捨て、Binを使う）\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize']\n",
        "combined = combined.drop(drop_elements, axis=1)\n",
        "\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "y_train = train_df[\"Survived\"].astype(int)\n",
        "X_test = test_df.drop(\"Survived\", axis=1)\n",
        "\n",
        "# 線形モデル（Logistic Regression）用にデータの縮尺を整える\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# =================================================\n",
        "# 4. 最強のアンサンブル（Voting）\n",
        "# =================================================\n",
        "print(\"★ 学習開始：3つの異なる頭脳を組み合わせます...\")\n",
        "\n",
        "# モデル1: Random Forest（安定感抜群）\n",
        "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# モデル2: LightGBM（高精度）\n",
        "clf_lgb = lgb.LGBMClassifier(objective='binary', verbose=-1, random_state=42)\n",
        "\n",
        "# モデル3: Logistic Regression（シンプル・イズ・ベスト）\n",
        "# ※過学習を抑える役割を果たします\n",
        "clf_lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# ★ 投票システム（VotingClassifier）\n",
        "# 'soft'投票は、確率の平均を取ります\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', clf_rf), ('lgb', clf_lgb), ('lr', clf_lr)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# 学習\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 交差検証スコアの確認\n",
        "scores = cross_val_score(voting_clf, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"==================================\")\n",
        "print(f\"Voting CV平均正解率: {scores.mean():.4f}\")\n",
        "print(f\"==================================\")\n",
        "\n",
        "# =================================================\n",
        "# 5. 提出\n",
        "# =================================================\n",
        "y_pred = voting_clf.predict(X_test_scaled)\n",
        "\n",
        "submission = pd.read_csv('test.csv')[['PassengerId']] # 元のファイルからIDだけ借りる\n",
        "submission['Survived'] = y_pred\n",
        "\n",
        "submission.to_csv('submission_best.csv', index=False)\n",
        "print(\"提出用ファイル 'submission_best.csv' が作成されました！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnAOUh1iKQxv",
        "outputId": "a41d142f-2770-48a1-a476-3efb303cda6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:21: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:21: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-1858645350.py:21: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
            "/tmp/ipython-input-1858645350.py:56: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
            "/tmp/ipython-input-1858645350.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ 学習開始：3つの異なる頭脳を組み合わせます...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\n",
            "Voting CV平均正解率: 0.8126\n",
            "==================================\n",
            "提出用ファイル 'submission_best.csv' が作成されました！\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission_best.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wasourRzKXlv",
        "outputId": "83ace805-a6b4-4304-b5a8-41f3c7f0b487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 14.6kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# =================================================\n",
        "# 1. データ準備（0.787を出したときと同じ処理）\n",
        "# =================================================\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# Title\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "combined['Title'] = combined['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "combined['Title'] = combined['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "combined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n",
        "combined['Title'] = combined['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).fillna(0)\n",
        "\n",
        "# Sex\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "\n",
        "# Age (Binning)\n",
        "combined['Age'] = combined['Age'].fillna(combined.groupby('Title')['Age'].transform('median'))\n",
        "combined['AgeBin'] = pd.cut(combined['Age'], 5, labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "# Embarked\n",
        "combined['Embarked'] = combined['Embarked'].fillna(combined['Embarked'].mode()[0])\n",
        "combined['Embarked'] = combined['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
        "\n",
        "# Fare (Binning)\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "combined['FareBin'] = pd.qcut(combined['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n",
        "\n",
        "# FamilySize & IsAlone\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "combined['IsAlone'] = 0\n",
        "combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
        "\n",
        "# 不要列の削除\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize']\n",
        "combined = combined.drop(drop_elements, axis=1)\n",
        "\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "y_train = train_df[\"Survived\"].astype(int)\n",
        "X_test = test_df.drop(\"Survived\", axis=1)\n",
        "\n",
        "# スケーリング（SVCやLogisticRegressionのために必須）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# =================================================\n",
        "# 2. スタッキング（Stacking）の構築\n",
        "# =================================================\n",
        "print(\"★ スタッキング学習を開始します...\")\n",
        "\n",
        "# 1層目のモデルたち（Base Models）\n",
        "level0 = list()\n",
        "level0.append(('lr', LogisticRegression(C=0.1, random_state=42)))\n",
        "level0.append(('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)))\n",
        "level0.append(('lgb', lgb.LGBMClassifier(n_estimators=100, max_depth=4, verbose=-1, random_state=42)))\n",
        "level0.append(('svm', SVC(probability=True, random_state=42))) # 新戦力：サポートベクターマシン\n",
        "\n",
        "# 2層目のモデル（Meta Model）：みんなの意見をまとめるリーダー\n",
        "# ここではロジスティック回帰が最適です\n",
        "level1 = LogisticRegression()\n",
        "\n",
        "# スタッキングモデルの定義\n",
        "model_stacking = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "\n",
        "# 学習\n",
        "model_stacking.fit(X_train_scaled, y_train)\n",
        "\n",
        "# =================================================\n",
        "# 3. 提出\n",
        "# =================================================\n",
        "y_pred = model_stacking.predict(X_test_scaled)\n",
        "\n",
        "submission = pd.read_csv('test.csv')[['PassengerId']]\n",
        "submission['Survived'] = y_pred\n",
        "submission.to_csv('submission_stacking.csv', index=False)\n",
        "\n",
        "print(\"提出用ファイル 'submission_stacking.csv' が作成されました！\")\n",
        "print(\"これが今の私たちに出せる、最強の一手です。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W6pB2XSLO30",
        "outputId": "2c4a9b61-321d-4040-b86c-07029b2ee8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-2409056787.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
            "/tmp/ipython-input-2409056787.py:41: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
            "/tmp/ipython-input-2409056787.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ スタッキング学習を開始します...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "提出用ファイル 'submission_stacking.csv' が作成されました！\n",
            "これが今の私たちに出せる、最強の一手です。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission_stacking.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxA1gE13LST4",
        "outputId": "2bd4db8a-3845-453e-ba19-6767ac7733f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 14.1kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# =================================================\n",
        "# 1. データ準備（前回と同じ0.79を出した構成）\n",
        "# =================================================\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# 特徴量エンジニアリング（省略なしで再現）\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "combined['Title'] = combined['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "combined['Title'] = combined['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "combined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n",
        "combined['Title'] = combined['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).fillna(0)\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "combined['Age'] = combined['Age'].fillna(combined.groupby('Title')['Age'].transform('median'))\n",
        "combined['AgeBin'] = pd.cut(combined['Age'], 5, labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "combined['Embarked'] = combined['Embarked'].fillna(combined['Embarked'].mode()[0])\n",
        "combined['Embarked'] = combined['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "combined['FareBin'] = pd.qcut(combined['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "combined['IsAlone'] = 0\n",
        "combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
        "\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize']\n",
        "combined = combined.drop(drop_elements, axis=1)\n",
        "\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "y_train = train_df[\"Survived\"].astype(int)\n",
        "X_test = test_df.drop(\"Survived\", axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# =================================================\n",
        "# 2. 最初のモデル学習（スタッキング）\n",
        "# =================================================\n",
        "print(\"★ Step 1: ベースモデルの学習中...\")\n",
        "\n",
        "level0 = [\n",
        "    ('lr', LogisticRegression(C=0.1, random_state=42)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "    ('lgb', lgb.LGBMClassifier(n_estimators=100, max_depth=4, verbose=-1, random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42))\n",
        "]\n",
        "level1 = LogisticRegression()\n",
        "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# =================================================\n",
        "# 3. Pseudo Labeling（ここが裏技！）\n",
        "# =================================================\n",
        "print(\"★ Step 2: 擬似ラベリング（Pseudo Labeling）を実行中...\")\n",
        "\n",
        "# テストデータに対する予測確率を出す\n",
        "y_test_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "# 自信満々のデータを探す\n",
        "# 0である確率が90%以上、または1である確率が90%以上のデータだけ抽出\n",
        "high_confidence_idx = np.where((y_test_proba[:, 0] > 0.9) | (y_test_proba[:, 1] > 0.9))[0]\n",
        "\n",
        "print(f\" -> テストデータ418件中、{len(high_confidence_idx)}件を「自信あり」として学習データに追加します。\")\n",
        "\n",
        "# 自信のあるテストデータを「擬似的な学習データ」として作成\n",
        "X_pseudo = X_test_scaled[high_confidence_idx]\n",
        "y_pseudo = np.argmax(y_test_proba[high_confidence_idx], axis=1) # 0か1に変換\n",
        "\n",
        "# 元の学習データと合体させる！\n",
        "X_train_pseudo = np.vstack((X_train_scaled, X_pseudo))\n",
        "y_train_pseudo = np.concatenate((y_train, y_pseudo))\n",
        "\n",
        "# =================================================\n",
        "# 4. 再学習と最終予測\n",
        "# =================================================\n",
        "print(\"★ Step 3: 増量したデータで再学習中...\")\n",
        "\n",
        "# パワーアップしたデータでもう一度学習\n",
        "model.fit(X_train_pseudo, y_train_pseudo)\n",
        "y_pred_final = model.predict(X_test_scaled)\n",
        "\n",
        "# 提出\n",
        "submission = pd.read_csv('test.csv')[['PassengerId']]\n",
        "submission['Survived'] = y_pred_final\n",
        "submission.to_csv('submission_pseudo.csv', index=False)\n",
        "\n",
        "print(\"提出用ファイル 'submission_pseudo.csv' が作成されました！\")\n",
        "print(\"さあ、0.8の壁を超えられるか……！？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAnhfsi6OBFX",
        "outputId": "b4e7f178-8a46-42bb-9ce6-489f4a5aebda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-4225301716.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
            "/tmp/ipython-input-4225301716.py:31: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
            "/tmp/ipython-input-4225301716.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ Step 1: ベースモデルの学習中...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ Step 2: 擬似ラベリング（Pseudo Labeling）を実行中...\n",
            " -> テストデータ418件中、85件を「自信あり」として学習データに追加します。\n",
            "★ Step 3: 増量したデータで再学習中...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "提出用ファイル 'submission_pseudo.csv' が作成されました！\n",
            "さあ、0.8の壁を超えられるか……！？\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission_pseudo.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_PVbmNpOkwe",
        "outputId": "6b479b56-5e85-472a-ddcc-f88d1cad28d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 15.7kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# =================================================\n",
        "# 1. データ準備（ベストスコア0.79186と同じ構成）\n",
        "# =================================================\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "combined = pd.concat([train_df, test_df], sort=False)\n",
        "\n",
        "# 特徴量エンジニアリング\n",
        "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "combined['Title'] = combined['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "combined['Title'] = combined['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "combined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n",
        "combined['Title'] = combined['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).fillna(0)\n",
        "combined['Sex'] = combined['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "combined['Age'] = combined['Age'].fillna(combined.groupby('Title')['Age'].transform('median'))\n",
        "combined['AgeBin'] = pd.cut(combined['Age'], 5, labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "combined['Embarked'] = combined['Embarked'].fillna(combined['Embarked'].mode()[0])\n",
        "combined['Embarked'] = combined['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
        "combined['Fare'] = combined['Fare'].fillna(combined['Fare'].median())\n",
        "combined['FareBin'] = pd.qcut(combined['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n",
        "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
        "combined['IsAlone'] = 0\n",
        "combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
        "\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize']\n",
        "combined = combined.drop(drop_elements, axis=1)\n",
        "\n",
        "train_df = combined.iloc[:len(train_df)]\n",
        "test_df = combined.iloc[len(train_df):]\n",
        "\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "y_train = train_df[\"Survived\"].astype(int)\n",
        "X_test = test_df.drop(\"Survived\", axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# =================================================\n",
        "# 2. Seed Averaging（10回の平均を取る！）\n",
        "# =================================================\n",
        "print(\"★ Seed Averagingを開始します（少し時間がかかります）...\")\n",
        "\n",
        "# 結果を足し合わせるための箱\n",
        "test_pred_prob_sum = np.zeros((len(X_test), 2)) # 0と1の確率を入れる箱\n",
        "\n",
        "# 10種類の異なる「運（SEED）」でモデルを回す\n",
        "seeds = [42, 2023, 123, 999, 7, 55, 101, 333, 777, 888]\n",
        "\n",
        "for i, seed in enumerate(seeds):\n",
        "    print(f\" -> Round {i+1}/{len(seeds)} (Seed: {seed})\")\n",
        "\n",
        "    # モデル定義（中身はベスト版と同じですが、random_stateだけ変えます）\n",
        "    level0 = [\n",
        "        ('lr', LogisticRegression(C=0.1, random_state=seed)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=seed)),\n",
        "        ('lgb', lgb.LGBMClassifier(n_estimators=100, max_depth=4, verbose=-1, random_state=seed)),\n",
        "        ('svm', SVC(probability=True, random_state=seed))\n",
        "    ]\n",
        "    level1 = LogisticRegression() # メタモデルはデフォルトでOK\n",
        "\n",
        "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # 確率を予測して足し込む\n",
        "    test_pred_prob_sum += model.predict_proba(X_test_scaled)\n",
        "\n",
        "# =================================================\n",
        "# 3. 平均をとって提出\n",
        "# =================================================\n",
        "# 10回分の合計を10で割って平均確率を出す\n",
        "final_proba = test_pred_prob_sum / len(seeds)\n",
        "\n",
        "# 0.5を境目に0か1かを決める\n",
        "y_pred_final = np.argmax(final_proba, axis=1)\n",
        "\n",
        "submission = pd.read_csv('test.csv')[['PassengerId']]\n",
        "submission['Survived'] = y_pred_final\n",
        "submission.to_csv('submission_seed_avg.csv', index=False)\n",
        "\n",
        "print(\"\\n提出用ファイル 'submission_seed_avg.csv' が作成されました！\")\n",
        "print(\"これが確率のブレを極限までなくした、最も信頼できる答えです。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYHMvWZqPKkF",
        "outputId": "748b51e0-a785-4b9b-9e3a-8c4a41e0a33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-1120458354.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
            "/tmp/ipython-input-1120458354.py:31: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n",
            "/tmp/ipython-input-1120458354.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  combined['IsAlone'].loc[combined['FamilySize'] == 1] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "★ Seed Averagingを開始します（少し時間がかかります）...\n",
            " -> Round 1/10 (Seed: 42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 2/10 (Seed: 2023)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 3/10 (Seed: 123)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 4/10 (Seed: 999)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 5/10 (Seed: 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 6/10 (Seed: 55)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 7/10 (Seed: 101)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 8/10 (Seed: 333)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 9/10 (Seed: 777)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Round 10/10 (Seed: 888)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "提出用ファイル 'submission_seed_avg.csv' が作成されました！\n",
            "これが確率のブレを極限までなくした、最も信頼できる答えです。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle APIを使って、submission.csvを直接提出するコマンド\n",
        "!kaggle competitions submit -c titanic -f submission_seed_avg.csv -m \"LightGBM + Optuna + Sex feature\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhkKl-3yP81j",
        "outputId": "f0067b90-da44-46fc-ce2b-98543b522777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 2.77k/2.77k [00:00<00:00, 14.1kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    }
  ]
}